{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic RNN\n",
    "- Objective: to understand basics of RNN & LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks\n",
    "- Feedforward neural networks (e.g. MLPs and CNNs) are powerful, but they are not optimized to handle \"sequential\" data\n",
    "- In other words, they do not possess \"memory\" of previous inputs\n",
    "- For instance, consider the case of translating a corpus. You need to consider the **\"context\"** to guess the next word to come forward\n",
    "\n",
    "<img src=\"http://2.bp.blogspot.com/-9GIdV292xV4/UwOIy6B6koI/AAAAAAAAHi4/X6UGlyHI-_U/s1600/tumblr_ms5qzpFY671r9nm7io1_500.gif\" style=\"width: 500px\"/>\n",
    "\n",
    "<br>\n",
    "- RNNs are suitable for dealing with sequential format data since they have **\"recurrent\"** structure\n",
    "- To put it differently, they keep the **\"memory\"** of earlier inputs in the sequence\n",
    "</br>\n",
    "<img src=\"http://www.wildml.com/wp-content/uploads/2015/09/rnn.jpg\" style=\"width: 600px\"/>\n",
    "\n",
    "<br>\n",
    "- However, in order to reduce the number of parameters, every layer of different time steps shares same parameters\n",
    "</br>\n",
    "\n",
    "<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png\" style=\"width: 600px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.datasets import reuters\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for data load\n",
    "num_words = 30000\n",
    "maxlen = 50\n",
    "test_split = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
      "2113536/2110848 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words = num_words, maxlen = maxlen, test_split = test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad the sequences with zeros \n",
    "# padding parameter is set to 'post' => 0's are appended to end of sequences\n",
    "X_train = pad_sequences(X_train, padding = 'post')\n",
    "X_test = pad_sequences(X_test, padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train).reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = np.array(X_test).reshape((X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = np.concatenate((y_train, y_test))\n",
    "y_data = to_categorical(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_data[:1395]\n",
    "y_test = y_data[1395:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1395, 49, 1)\n",
      "(599, 49, 1)\n",
      "(1395, 46)\n",
      "(599, 46)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Vanilla RNN\n",
    "- Vanilla RNNs have a simple structure\n",
    "- However, they suffer from the problem of \"long-term dependencies\"\n",
    "- Hence, they are not able to keep the **sequential memory\" for long\n",
    "\n",
    "<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-SimpleRNN.png\" style=\"width: 600px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, Activation\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vanilla_rnn():\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(50, input_shape = (49,1), return_sequences = False))\n",
    "    model.add(Dense(46)) # 46개의 OUTPUT 을 가지는 DENSE 측\n",
    "    model.add(Activation('softmax')) # softmax 의 activation\n",
    "    \n",
    "    adam = optimizers.Adam(lr = 0.001)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn = vanilla_rnn, epochs = 100, batch_size = 50, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 3.5011 - accuracy: 0.3161\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 1.8918 - accuracy: 0.6738\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 1.3323 - accuracy: 0.6903\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 1.2089 - accuracy: 0.7147\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 1.1794 - accuracy: 0.7147\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 1.1667 - accuracy: 0.7147\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 1.1596 - accuracy: 0.7147\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 1.1562 - accuracy: 0.7147\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 1.1540 - accuracy: 0.7147\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 1.1517 - accuracy: 0.7147 0s - loss: 1.1918 - accuracy: \n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 1.1509 - accuracy: 0.7147\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 1.1508 - accuracy: 0.7147\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 1.1482 - accuracy: 0.7147\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 1.1502 - accuracy: 0.7147\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 1.1462 - accuracy: 0.7147\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 1.1452 - accuracy: 0.7147\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 1.1450 - accuracy: 0.7147\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 1.1444 - accuracy: 0.7147\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 1.1429 - accuracy: 0.7147\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 1.1436 - accuracy: 0.7147\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 1.1426 - accuracy: 0.7147\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 1.1421 - accuracy: 0.7147\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 1.1395 - accuracy: 0.7147\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 1.1389 - accuracy: 0.7147\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 1.1393 - accuracy: 0.7147\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 1.1428 - accuracy: 0.7147\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 1.1405 - accuracy: 0.7147\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 1.1394 - accuracy: 0.7147\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 1.1381 - accuracy: 0.7147\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 1.1376 - accuracy: 0.7147\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.1344 - accuracy: 0.7147\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.1352 - accuracy: 0.7147\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 1.1364 - accuracy: 0.7147\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 1.1335 - accuracy: 0.7147\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 1.1334 - accuracy: 0.7147\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 1.1313 - accuracy: 0.7125\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.1316 - accuracy: 0.7161\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.1322 - accuracy: 0.7147\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.1311 - accuracy: 0.7147\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.1292 - accuracy: 0.7176\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.1261 - accuracy: 0.7161\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.1184 - accuracy: 0.7161\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.1070 - accuracy: 0.7147\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.1290 - accuracy: 0.7176\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.1208 - accuracy: 0.7190\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.1121 - accuracy: 0.7154\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0981 - accuracy: 0.7147\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.1034 - accuracy: 0.7154\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.0732 - accuracy: 0.7147\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.0576 - accuracy: 0.7154\n",
      "Epoch 51/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 1.0477 - accuracy: 0.7147\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 1.0419 - accuracy: 0.7183\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 1.0301 - accuracy: 0.7161\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 1.0235 - accuracy: 0.7168 0s - loss: 1.0067 - accuracy: \n",
      "Epoch 55/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 1.0214 - accuracy: 0.7269\n",
      "Epoch 56/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 1.0454 - accuracy: 0.7183\n",
      "Epoch 57/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 1.0400 - accuracy: 0.7168\n",
      "Epoch 58/100\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.0239 - accuracy: 0.7161\n",
      "Epoch 59/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 1.0119 - accuracy: 0.7133\n",
      "Epoch 60/100\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 0.9945 - accuracy: 0.7168\n",
      "Epoch 61/100\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0136 - accuracy: 0.7290\n",
      "Epoch 62/100\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 1.0090 - accuracy: 0.7197\n",
      "Epoch 63/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 0.9991 - accuracy: 0.7219\n",
      "Epoch 64/100\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.0004 - accuracy: 0.7219\n",
      "Epoch 65/100\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 0.9910 - accuracy: 0.7254\n",
      "Epoch 66/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.9798 - accuracy: 0.7219\n",
      "Epoch 67/100\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 0.9728 - accuracy: 0.7226\n",
      "Epoch 68/100\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 0.9703 - accuracy: 0.7319\n",
      "Epoch 69/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 0.9823 - accuracy: 0.7269\n",
      "Epoch 70/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 0.9752 - accuracy: 0.7297\n",
      "Epoch 71/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 0.9782 - accuracy: 0.7226\n",
      "Epoch 72/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 0.9693 - accuracy: 0.7312\n",
      "Epoch 73/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 0.9725 - accuracy: 0.7269\n",
      "Epoch 74/100\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 0.9624 - accuracy: 0.7269\n",
      "Epoch 75/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.9738 - accuracy: 0.7319\n",
      "Epoch 76/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 0.9659 - accuracy: 0.7341\n",
      "Epoch 77/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 0.9565 - accuracy: 0.7312\n",
      "Epoch 78/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 0.9609 - accuracy: 0.7283\n",
      "Epoch 79/100\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 0.9495 - accuracy: 0.7333\n",
      "Epoch 80/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 0.9447 - accuracy: 0.7326\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 10ms/step - loss: 0.9496 - accuracy: 0.7333\n",
      "Epoch 82/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 0.9511 - accuracy: 0.7305\n",
      "Epoch 83/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 0.9349 - accuracy: 0.7369\n",
      "Epoch 84/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 0.9347 - accuracy: 0.7376\n",
      "Epoch 85/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 0.9317 - accuracy: 0.7355\n",
      "Epoch 86/100\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 0.9591 - accuracy: 0.7312\n",
      "Epoch 87/100\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 0.9264 - accuracy: 0.7362\n",
      "Epoch 88/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 0.9300 - accuracy: 0.7283\n",
      "Epoch 89/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 0.9237 - accuracy: 0.7290\n",
      "Epoch 90/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 0.9295 - accuracy: 0.7305\n",
      "Epoch 91/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 0.9181 - accuracy: 0.7341\n",
      "Epoch 92/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 0.9477 - accuracy: 0.7326\n",
      "Epoch 93/100\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 0.9153 - accuracy: 0.7355\n",
      "Epoch 94/100\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 0.9130 - accuracy: 0.7319\n",
      "Epoch 95/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 0.9147 - accuracy: 0.7283\n",
      "Epoch 96/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 0.9175 - accuracy: 0.7341\n",
      "Epoch 97/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 0.9115 - accuracy: 0.7341\n",
      "Epoch 98/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 0.8955 - accuracy: 0.7355\n",
      "Epoch 99/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 0.8954 - accuracy: 0.7312\n",
      "Epoch 100/100\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 0.8890 - accuracy: 0.7333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a865bc7f08>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\goran\\Anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\keras\\wrappers\\scikit_learn.py:241: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "12/12 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_ = np.argmax(y_test, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7445742904841403\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_pred, y_test_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Stacked Vanilla RNN\n",
    "- RNN layers can be stacked to form a deeper network\n",
    "\n",
    "<img src=\"https://lh6.googleusercontent.com/rC1DSgjlmobtRxMPFi14hkMdDqSkEkuOX7EW_QrLFSymjasIM95Za2Wf-VwSC1Tq1sjJlOPLJ92q7PTKJh2hjBoXQawM6MQC27east67GFDklTalljlt0cFLZnPMdhp8erzO\" style=\"width: 500px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stacked_vanilla_rnn():\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(50, input_shape = (49,1), return_sequences = True))   # return_sequences parameter has to be set True to stack\n",
    "    model.add(SimpleRNN(50, return_sequences = False))\n",
    "    model.add(Dense(46))\n",
    "    model.add(Activation('softmax'))\n",
    "    adam = optimizers.Adam(lr = 0.001)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn = stacked_vanilla_rnn, epochs = 200, batch_size = 50, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/599 [========================>.....] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.746243739566\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_pred, y_test_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LSTM\n",
    "- LSTM (long short-term memory) is an improved structure to solve the problem of long-term dependencies\n",
    "\n",
    "<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png\" style=\"width: 600px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lstm():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, input_shape = (49,1), return_sequences = False))\n",
    "    model.add(Dense(46))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    adam = optimizers.Adam(lr = 0.001)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn = lstm, epochs = 200, batch_size = 50, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/599 [========================>.....] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.844741235392\n"
     ]
    }
   ],
   "source": [
    "# accuracy improves by adopting LSTM structure\n",
    "print(accuracy_score(y_pred, y_test_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Stacked LSTM\n",
    "- LSTM layers can be stacked as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stacked_lstm():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, input_shape = (49,1), return_sequences = True))\n",
    "    model.add(LSTM(50, return_sequences = False))\n",
    "    model.add(Dense(46))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    adam = optimizers.Adam(lr = 0.001)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn = stacked_lstm, epochs = 200, batch_size = 50, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/599 [========================>.....] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.858096828047\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_pred, y_test_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
